{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: Equal Parameters Comparison\n",
    "## STGNN vs Transformer vs Hybrid dengan Jumlah Parameter SAMA (~350K)\n",
    "\n",
    "Perbandingan yang benar-benar fair - semua model punya kapasitas yang setara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MAHARDIKA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "import os, gc, json, time, random, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Libraries loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "ROOT = Path('DatasetTA')\n",
    "GRAPHS_DIR = ROOT / 'project_data' / 'graphs'\n",
    "MODELS_DIR = ROOT / 'project_data' / 'models'\n",
    "ANALYSIS_DIR = ROOT / 'project_data' / 'analysis'\n",
    "for p in [MODELS_DIR, ANALYSIS_DIR]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "# Training config\n",
    "EPOCHS = 15\n",
    "LR = 5e-4\n",
    "BATCH_ACCUM = 4\n",
    "MAX_SEGMENTS = 8\n",
    "MAX_NODES = 300\n",
    "PATIENCE = 5\n",
    "LABEL_SMOOTHING = 0.1\n",
    "DROPOUT = 0.3\n",
    "\n",
    "ANOM_CLASSES = ['Abuse','Arrest','Arson','Assault','Burglary','Explosion',\n",
    "                'Fighting','Robbery','Shooting','Shoplifting','Stealing','Vandalism']\n",
    "\n",
    "print(f'Device: {DEVICE}')\n",
    "print(f'Graphs: {GRAPHS_DIR}')\n",
    "print(f'Target: ~350K parameters per model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Count Verification:\n",
      "==================================================\n",
      "STGNN Only (Scaled):          345,733 params\n",
      "Transformer Only (Scaled):    323,715 params\n",
      "Hybrid (Original):            350,147 params\n",
      "==================================================\n",
      "Average: 339,865 params\n",
      "Max diff: 4.8%\n",
      "✅ Parameters are well balanced!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STGNN Only - Tuned to ~350K params\n",
    "# =============================================================================\n",
    "class STGNNOnlyScaled(nn.Module):\n",
    "    def __init__(self, hidden_dim=220, output_dim=220, gcn_layers=5):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(10, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        self.convs = nn.ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(gcn_layers)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(gcn_layers)])\n",
    "        self.att = nn.Sequential(nn.Linear(hidden_dim, hidden_dim//2), nn.Tanh(), nn.Linear(hidden_dim//2, 1))\n",
    "        self.proj = nn.Linear(hidden_dim, output_dim)\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim//2), nn.GELU(), nn.Dropout(DROPOUT), nn.Linear(output_dim//2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward_single(self, x, ei):\n",
    "        h = self.enc(norm_feat(x))\n",
    "        for conv, ln in zip(self.convs, self.norms):\n",
    "            h = h + F.gelu(ln(conv(h, ei)))\n",
    "        att = torch.softmax(self.att(h).squeeze(-1), 0)\n",
    "        return self.proj((h * att.unsqueeze(-1)).sum(0, keepdim=True))\n",
    "    \n",
    "    def forward(self, segs):\n",
    "        dev = next(self.parameters()).device\n",
    "        feats = [self.forward_single(\n",
    "            g.x.to(dev), \n",
    "            g.edge_index.to(dev) if g.edge_index.numel()>0 else torch.empty((2,0), dtype=torch.long, device=dev)\n",
    "        ) for g in segs]\n",
    "        return self.cls(torch.cat(feats, 0).mean(0, keepdim=True))\n",
    "\n",
    "# =============================================================================\n",
    "# Transformer Only - Tuned to ~350K params (smaller MLP)\n",
    "# =============================================================================\n",
    "class TransformerOnlyScaled(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, output_dim=128, trans_layers=1, heads=4):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(10, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        self.att = nn.Sequential(nn.Linear(hidden_dim, hidden_dim//2), nn.Tanh(), nn.Linear(hidden_dim//2, 1))\n",
    "        self.proj = nn.Linear(hidden_dim, output_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(output_dim, heads, output_dim*2, DROPOUT, 'gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, trans_layers)\n",
    "        # MLP sized to reach ~350K total\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(output_dim, 256), nn.GELU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(256, 192), nn.GELU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(192, output_dim)\n",
    "        )\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim//2), nn.GELU(), nn.Dropout(DROPOUT), nn.Linear(output_dim//2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward_single(self, x):\n",
    "        h = self.enc(norm_feat(x))\n",
    "        att = torch.softmax(self.att(h).squeeze(-1), 0)\n",
    "        return self.proj((h * att.unsqueeze(-1)).sum(0, keepdim=True))\n",
    "    \n",
    "    def forward(self, segs):\n",
    "        dev = next(self.parameters()).device\n",
    "        feats = [self.forward_single(g.x.to(dev)) for g in segs]\n",
    "        seq = torch.cat(feats, 0).unsqueeze(0)\n",
    "        out = self.transformer(seq).mean(1)\n",
    "        out = self.mlp1(out)\n",
    "        return self.cls(out)\n",
    "\n",
    "# =============================================================================\n",
    "# Hybrid STGNN + Transformer - Original ~350K params\n",
    "# =============================================================================\n",
    "class HybridOriginal(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, output_dim=128, gcn_layers=3, trans_layers=2, heads=4):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(10, hidden_dim), nn.LayerNorm(hidden_dim), nn.GELU(), nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        self.convs = nn.ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(gcn_layers)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(gcn_layers)])\n",
    "        self.att = nn.Sequential(nn.Linear(hidden_dim, hidden_dim//2), nn.Tanh(), nn.Linear(hidden_dim//2, 1))\n",
    "        self.proj = nn.Linear(hidden_dim, output_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(output_dim, heads, output_dim*2, DROPOUT, 'gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, trans_layers)\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim//2), nn.GELU(), nn.Dropout(DROPOUT), nn.Linear(output_dim//2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward_stgnn(self, x, ei):\n",
    "        h = self.enc(norm_feat(x))\n",
    "        for conv, ln in zip(self.convs, self.norms):\n",
    "            h = h + F.gelu(ln(conv(h, ei)))\n",
    "        att = torch.softmax(self.att(h).squeeze(-1), 0)\n",
    "        return self.proj((h * att.unsqueeze(-1)).sum(0, keepdim=True))\n",
    "    \n",
    "    def forward(self, segs):\n",
    "        dev = next(self.parameters()).device\n",
    "        feats = [self.forward_stgnn(\n",
    "            g.x.to(dev), \n",
    "            g.edge_index.to(dev) if g.edge_index.numel()>0 else torch.empty((2,0), dtype=torch.long, device=dev)\n",
    "        ) for g in segs]\n",
    "        seq = torch.cat(feats, 0).unsqueeze(0)\n",
    "        return self.cls(self.transformer(seq).mean(1))\n",
    "\n",
    "print('Model classes defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "def augment_features(x):\n",
    "    if x.size(1) == 5:\n",
    "        x1,y1,x2,y2,conf = x[:,0],x[:,1],x[:,2],x[:,3],x[:,4]\n",
    "        w, h = (x2-x1).clamp(min=1), (y2-y1).clamp(min=1)\n",
    "        x = torch.cat([x, w.unsqueeze(1), h.unsqueeze(1), (w*h).unsqueeze(1),\n",
    "                       (0.5*(x1+x2)).unsqueeze(1), (0.5*(y1+y2)).unsqueeze(1)], dim=1)\n",
    "    return x\n",
    "\n",
    "def norm_feat(x):\n",
    "    x = augment_features(x)\n",
    "    fmin, fmax = x.min(0).values, x.max(0).values\n",
    "    return (x - fmin) / (fmax - fmin).clamp(min=1e-6)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.ls = alpha, gamma, label_smoothing\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.alpha, label_smoothing=self.ls, reduction='none')\n",
    "        return (((1 - torch.exp(-ce)) ** self.gamma) * ce).mean()\n",
    "\n",
    "def limit_nodes(g, max_nodes=MAX_NODES):\n",
    "    if g.x.size(0) <= max_nodes: return g\n",
    "    idx = torch.randperm(g.x.size(0))[:max_nodes].sort().values\n",
    "    N = g.x.size(0)\n",
    "    mask = torch.zeros(N, dtype=torch.bool); mask[idx] = True\n",
    "    if g.edge_index.numel() > 0:\n",
    "        em = mask[g.edge_index[0]] & mask[g.edge_index[1]]\n",
    "        ei = g.edge_index[:, em]\n",
    "        mapping = torch.zeros(N, dtype=torch.long); mapping[idx] = torch.arange(len(idx))\n",
    "        ei = mapping[ei]\n",
    "    else:\n",
    "        ei = torch.empty((2,0), dtype=torch.long)\n",
    "    return Data(x=g.x[idx], edge_index=ei)\n",
    "\n",
    "def split_segments(g, max_seg=MAX_SEGMENTS):\n",
    "    g = limit_nodes(g)\n",
    "    if not hasattr(g, 'frame_ids') or g.frame_ids is None: return [g]\n",
    "    fids = g.frame_ids.numpy() if isinstance(g.frame_ids, torch.Tensor) else np.array(g.frame_ids)\n",
    "    unique = np.unique(fids)\n",
    "    chosen = unique if len(unique) <= max_seg else unique[np.linspace(0, len(unique)-1, max_seg, dtype=int)]\n",
    "    segs = []\n",
    "    for f in chosen:\n",
    "        m = fids == f\n",
    "        if m.sum() == 0: continue\n",
    "        idx = np.where(m)[0]\n",
    "        x = g.x[idx]\n",
    "        if g.edge_index.numel() > 0:\n",
    "            em = torch.isin(g.edge_index[0], torch.tensor(idx)) & torch.isin(g.edge_index[1], torch.tensor(idx))\n",
    "            ei = g.edge_index[:, em]\n",
    "            if ei.numel() > 0:\n",
    "                mapping = torch.zeros(g.x.size(0), dtype=torch.long)\n",
    "                mapping[idx] = torch.arange(len(idx))\n",
    "                ei = mapping[ei]\n",
    "            else: ei = torch.empty((2,0), dtype=torch.long)\n",
    "        else: ei = torch.empty((2,0), dtype=torch.long)\n",
    "        segs.append(Data(x=x, edge_index=ei))\n",
    "    return segs if segs else [limit_nodes(g)]\n",
    "\n",
    "print('Utility functions defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_NODES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m         ce = F.cross_entropy(logits, targets, weight=\u001b[38;5;28mself\u001b[39m.alpha, label_smoothing=\u001b[38;5;28mself\u001b[39m.ls, reduction=\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (((\u001b[32m1\u001b[39m - torch.exp(-ce)) ** \u001b[38;5;28mself\u001b[39m.gamma) * ce).mean()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlimit_nodes\u001b[39m(g, max_nodes=\u001b[43mMAX_NODES\u001b[49m):\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m g.x.size(\u001b[32m0\u001b[39m) <= max_nodes: \u001b[38;5;28;01mreturn\u001b[39;00m g\n\u001b[32m     24\u001b[39m     idx = torch.randperm(g.x.size(\u001b[32m0\u001b[39m))[:max_nodes].sort().values\n",
      "\u001b[31mNameError\u001b[39m: name 'MAX_NODES' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET\n",
    "# =============================================================================\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_dir, split='train'):\n",
    "        self.files = sorted(list(graph_dir.rglob('*_graph.pt')))\n",
    "        random.Random(SEED).shuffle(self.files)\n",
    "        n = int(0.85 * len(self.files))\n",
    "        self.files = self.files[:n] if split == 'train' else self.files[n:]\n",
    "    def __len__(self): return len(self.files)\n",
    "    def __getitem__(self, i):\n",
    "        g = torch.load(self.files[i], weights_only=False)\n",
    "        label = 1 if any(c in self.files[i].stem for c in ANOM_CLASSES) else 0\n",
    "        return g, label, self.files[i].stem\n",
    "\n",
    "# Load dataset\n",
    "train_ds = GraphDataset(GRAPHS_DIR, 'train')\n",
    "val_ds = GraphDataset(GRAPHS_DIR, 'val')\n",
    "print(f'Train: {len(train_ds)} | Val: {len(val_ds)}')\n",
    "\n",
    "train_labels = [train_ds[i][1] for i in range(len(train_ds))]\n",
    "n0, n1 = train_labels.count(0), train_labels.count(1)\n",
    "print(f'Class distribution - Normal: {n0} ({n0/(n0+n1)*100:.1f}%) | Anomaly: {n1} ({n1/(n0+n1)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify parameter counts\n",
    "print('Parameter Count Verification:')\n",
    "print('='*50)\n",
    "m1 = STGNNOnlyScaled()\n",
    "m2 = TransformerOnlyScaled()\n",
    "m3 = HybridOriginal()\n",
    "p1 = sum(p.numel() for p in m1.parameters())\n",
    "p2 = sum(p.numel() for p in m2.parameters())\n",
    "p3 = sum(p.numel() for p in m3.parameters())\n",
    "print(f'STGNN Only (Scaled):       {p1:>10,} params')\n",
    "print(f'Transformer Only (Scaled): {p2:>10,} params')\n",
    "print(f'Hybrid (Original):         {p3:>10,} params')\n",
    "print('='*50)\n",
    "avg = (p1+p2+p3)//3\n",
    "diff_pct = max(abs(p1-avg), abs(p2-avg), abs(p3-avg))/avg*100\n",
    "print(f'Average: {avg:,} params')\n",
    "print(f'Max diff: {diff_pct:.1f}%')\n",
    "if diff_pct < 5:\n",
    "    print('✅ Parameters are well balanced!')\n",
    "elif diff_pct < 15:\n",
    "    print('✅ Parameters are acceptable')\n",
    "else:\n",
    "    print('⚠️ Parameters need more tuning')\n",
    "del m1, m2, m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter Count Verification:\n",
      "==================================================\n",
      "STGNN Only (Scaled):        400,515 params\n",
      "Transformer Only (Scaled):  2,243,715 params\n",
      "Hybrid (Original):          350,147 params\n",
      "==================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, ds, opt, crit, scaler, dev):\n",
    "    model.train()\n",
    "    loss_sum, correct, n = 0, 0, 0\n",
    "    opt.zero_grad()\n",
    "    for i, (g, lab, _) in enumerate(tqdm(ds, leave=False, desc='Train')):\n",
    "        segs = split_segments(g)\n",
    "        y = torch.tensor([lab], dtype=torch.long, device=dev)\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits = model(segs)\n",
    "            loss = crit(logits, y) / BATCH_ACCUM\n",
    "        scaler.scale(loss).backward()\n",
    "        if (i+1) % BATCH_ACCUM == 0 or i+1 == len(ds):\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(opt); scaler.update(); opt.zero_grad()\n",
    "        loss_sum += loss.item() * BATCH_ACCUM\n",
    "        correct += int(logits.argmax(1).item() == lab)\n",
    "        n += 1\n",
    "        if i % 50 == 0: torch.cuda.empty_cache()\n",
    "    return loss_sum/n, correct/n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, ds, crit, dev):\n",
    "    model.eval()\n",
    "    loss_sum, correct, n = 0, 0, 0\n",
    "    ys, ps = [], []\n",
    "    for i, (g, lab, _) in enumerate(tqdm(ds, leave=False, desc='Eval')):\n",
    "        segs = split_segments(g)\n",
    "        y = torch.tensor([lab], dtype=torch.long, device=dev)\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits = model(segs)\n",
    "            loss = crit(logits, y)\n",
    "        prob = torch.softmax(logits, 1)[0, 1].item()\n",
    "        loss_sum += loss.item()\n",
    "        correct += int(logits.argmax(1).item() == lab)\n",
    "        ys.append(lab); ps.append(prob)\n",
    "        n += 1\n",
    "        if i % 50 == 0: torch.cuda.empty_cache()\n",
    "    auc = roc_auc_score(ys, ps) if len(set(ys)) > 1 else 0.5\n",
    "    # Find best threshold\n",
    "    thr_range = np.linspace(0.1, 0.9, 50)\n",
    "    f1_scores = [f1_score(ys, [1 if p >= t else 0 for p in ps], zero_division=0) for t in thr_range]\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_thr, best_f1 = thr_range[best_idx], f1_scores[best_idx]\n",
    "    preds = [1 if p >= best_thr else 0 for p in ps]\n",
    "    prec = precision_score(ys, preds, zero_division=0)\n",
    "    rec = recall_score(ys, preds, zero_division=0)\n",
    "    return {'loss': loss_sum/n, 'acc': correct/n, 'auc': auc, 'f1': best_f1, \n",
    "            'precision': prec, 'recall': rec, 'thr': best_thr, 'ys': ys, 'ps': ps, 'preds': preds}\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_inference_time(model, ds, dev, num_samples=50, warmup=5):\n",
    "    model.eval(); model = model.to(dev)\n",
    "    for i in range(min(warmup, len(ds))):\n",
    "        g, _, _ = ds[i]\n",
    "        segs = split_segments(g)\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP): _ = model(segs)\n",
    "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "    times = []\n",
    "    for i in range(min(num_samples, len(ds))):\n",
    "        g, _, _ = ds[i]\n",
    "        segs = split_segments(g)\n",
    "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "        start = time.perf_counter()\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP): _ = model(segs)\n",
    "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "        times.append((time.perf_counter() - start) * 1000)\n",
    "    return {'mean_ms': np.mean(times), 'std_ms': np.std(times), 'fps': 1000 / np.mean(times)}\n",
    "\n",
    "def train_model(model, model_name, train_ds, val_ds, dev):\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Training: {model_name}')\n",
    "    print(f'Parameters: {params:,}')\n",
    "    print('='*60)\n",
    "    \n",
    "    model = model.to(dev)\n",
    "    labels = [train_ds[i][1] for i in range(len(train_ds))]\n",
    "    n0, n1 = labels.count(0), labels.count(1)\n",
    "    total = n0 + n1\n",
    "    weights = torch.tensor([n1/total, n0/total], device=dev) if total > 0 else torch.tensor([0.5, 0.5], device=dev)\n",
    "    \n",
    "    crit = FocalLoss(alpha=weights, gamma=2.0, label_smoothing=LABEL_SMOOTHING)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, EPOCHS)\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=USE_AMP)\n",
    "    \n",
    "    best_auc, patience_counter = 0, 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n",
    "    save_name = model_name.lower().replace(' ', '_').replace('+', '_').replace('-', '_')\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_epoch(model, train_ds, opt, crit, scaler, dev)\n",
    "        val_res = evaluate(model, val_ds, crit, dev)\n",
    "        sched.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_res['loss'])\n",
    "        history['val_acc'].append(val_res['acc'])\n",
    "        history['val_auc'].append(val_res['auc'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss:.4f} | Val Acc: {val_res['acc']*100:.1f}% | Val AUC: {val_res['auc']:.4f} | Val F1: {val_res['f1']:.4f}\")\n",
    "        \n",
    "        if val_res['auc'] > best_auc:\n",
    "            best_auc = val_res['auc']\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), MODELS_DIR / f'equal_{save_name}.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "    \n",
    "    # Load best model and final eval\n",
    "    model.load_state_dict(torch.load(MODELS_DIR / f'equal_{save_name}.pt', weights_only=True))\n",
    "    final_res = evaluate(model, val_ds, crit, dev)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'params': params,\n",
    "        'best_auc': best_auc,\n",
    "        'accuracy': final_res['acc'],\n",
    "        'precision': final_res['precision'],\n",
    "        'recall': final_res['recall'],\n",
    "        'best_f1': final_res['f1'],\n",
    "        'best_thr': final_res['thr'],\n",
    "        'history': history,\n",
    "        'ys': final_res['ys'],\n",
    "        'ps': final_res['ps'],\n",
    "        'preds': final_res['preds']\n",
    "    }\n",
    "\n",
    "print('Training functions defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. STGNN Only (Scaled)\u001b[39;00m\n\u001b[32m      4\u001b[39m model = STGNNOnlyScaled()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = train_model(model, \u001b[33m'\u001b[39m\u001b[33mSTGNN Only (Scaled)\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mtrain_ds\u001b[49m, val_ds, DEVICE)\n\u001b[32m      6\u001b[39m result.update(measure_inference_time(model, val_ds, DEVICE))\n\u001b[32m      7\u001b[39m results.append(result)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# 1. STGNN Only (Scaled)\n",
    "model = STGNNOnlyScaled()\n",
    "result = train_model(model, 'STGNN Only (Scaled)', train_ds, val_ds, DEVICE)\n",
    "result.update(measure_inference_time(model, val_ds, DEVICE))\n",
    "results.append(result)\n",
    "del model; torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "# 2. Transformer Only (Scaled)\n",
    "model = TransformerOnlyScaled()\n",
    "result = train_model(model, 'Transformer Only (Scaled)', train_ds, val_ds, DEVICE)\n",
    "result.update(measure_inference_time(model, val_ds, DEVICE))\n",
    "results.append(result)\n",
    "del model; torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "# 3. Hybrid (Original)\n",
    "model = HybridOriginal()\n",
    "result = train_model(model, 'Hybrid STGNN+Transformer', train_ds, val_ds, DEVICE)\n",
    "result.update(measure_inference_time(model, val_ds, DEVICE))\n",
    "results.append(result)\n",
    "del model; torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('TRAINING COMPLETE!')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*100)\n",
    "print('HASIL BENCHMARK: EQUAL PARAMETERS COMPARISON')\n",
    "print('='*100)\n",
    "print(f'{\"Model\":<30} | {\"Params\":>10} | {\"Accuracy\":>8} | {\"AUC-ROC\":>8} | {\"F1\":>8} | {\"Precision\":>9} | {\"Recall\":>8} | {\"Time(ms)\":>9}')\n",
    "print('-'*100)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['model_name']:<30} | {r['params']:>10,} | {r['accuracy']*100:>7.2f}% | {r['best_auc']:>8.4f} | {r['best_f1']:>8.4f} | {r['precision']:>9.4f} | {r['recall']:>8.4f} | {r['mean_ms']:>9.2f}\")\n",
    "\n",
    "print('-'*100)\n",
    "best = max(results, key=lambda x: x['best_auc'])\n",
    "print(f\"\\nBest Model: {best['model_name']} (AUC: {best['best_auc']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization: Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "labels = ['STGNN (Scaled)', 'Transformer (Scaled)', 'Hybrid']\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    epochs = range(1, len(r['history']['train_loss'])+1)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(epochs, r['history']['train_loss'], '-', color=colors[idx], alpha=0.5, label=f\"{labels[idx]} (Train)\")\n",
    "    axes[0].plot(epochs, r['history']['val_loss'], '--', color=colors[idx], linewidth=2, label=f\"{labels[idx]} (Val)\")\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(epochs, [a*100 for a in r['history']['val_acc']], '-o', color=colors[idx], linewidth=2, label=labels[idx])\n",
    "    \n",
    "    # AUC\n",
    "    axes[2].plot(epochs, r['history']['val_auc'], '-o', color=colors[idx], linewidth=2, label=labels[idx])\n",
    "\n",
    "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='upper right', fontsize=8); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('AUC-ROC')\n",
    "axes[2].set_title('Validation AUC-ROC', fontsize=12, fontweight='bold')\n",
    "axes[2].legend(); axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training History - Equal Parameters Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ANALYSIS_DIR / 'equal_params_training_history.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization: ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    fpr, tpr, _ = roc_curve(r['ys'], r['ps'])\n",
    "    ax.plot(fpr, tpr, color=colors[idx], linewidth=2.5, \n",
    "            label=f\"{labels[idx]} (AUC={r['best_auc']:.4f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves - Equal Parameters Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([0, 1]); ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ANALYSIS_DIR / 'equal_params_roc_curves.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    cm = confusion_matrix(r['ys'], r['preds'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "               xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'],\n",
    "               annot_kws={'size': 16, 'weight': 'bold'})\n",
    "    axes[idx].set_xlabel('Predicted', fontsize=11)\n",
    "    axes[idx].set_ylabel('Actual', fontsize=11)\n",
    "    axes[idx].set_title(f\"{labels[idx]}\\nAcc: {r['accuracy']*100:.1f}% | F1: {r['best_f1']:.3f}\", \n",
    "                        fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - Equal Parameters Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ANALYSIS_DIR / 'equal_params_confusion_matrices.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization: Performance Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "model_names = [labels[i] for i in range(3)]\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "# AUC-ROC\n",
    "aucs = [r['best_auc'] for r in results]\n",
    "bars = axes[0,0].bar(x, aucs, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0,0].set_ylabel('AUC-ROC', fontsize=11)\n",
    "axes[0,0].set_title('AUC-ROC Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_xticks(x); axes[0,0].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[0,0].set_ylim(0.5, 1.0); axes[0,0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(aucs): axes[0,0].text(i, v+0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Accuracy\n",
    "accs = [r['accuracy']*100 for r in results]\n",
    "axes[0,1].bar(x, accs, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0,1].set_ylabel('Accuracy (%)', fontsize=11)\n",
    "axes[0,1].set_title('Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_xticks(x); axes[0,1].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[0,1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(accs): axes[0,1].text(i, v+0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# F1-Score\n",
    "f1s = [r['best_f1'] for r in results]\n",
    "axes[0,2].bar(x, f1s, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0,2].set_ylabel('F1-Score', fontsize=11)\n",
    "axes[0,2].set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0,2].set_xticks(x); axes[0,2].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[0,2].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(f1s): axes[0,2].text(i, v+0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Precision\n",
    "precs = [r['precision'] for r in results]\n",
    "axes[1,0].bar(x, precs, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1,0].set_ylabel('Precision', fontsize=11)\n",
    "axes[1,0].set_title('Precision Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_xticks(x); axes[1,0].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(precs): axes[1,0].text(i, v+0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Recall\n",
    "recs = [r['recall'] for r in results]\n",
    "axes[1,1].bar(x, recs, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1,1].set_ylabel('Recall', fontsize=11)\n",
    "axes[1,1].set_title('Recall Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_xticks(x); axes[1,1].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(recs): axes[1,1].text(i, v+0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Inference Time\n",
    "times = [r['mean_ms'] for r in results]\n",
    "axes[1,2].bar(x, times, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1,2].set_ylabel('Inference Time (ms)', fontsize=11)\n",
    "axes[1,2].set_title('Inference Time Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1,2].set_xticks(x); axes[1,2].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "axes[1,2].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(times): axes[1,2].text(i, v+0.5, f'{v:.1f}ms', ha='center', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Performance Metrics - Equal Parameters Comparison (~350K params each)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(ANALYSIS_DIR / 'equal_params_performance_comparison.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization: Parameters vs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "params = [r['params']/1000 for r in results]\n",
    "aucs = [r['best_auc'] for r in results]\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "    ax.scatter(params[idx], aucs[idx], s=300, c=colors[idx], edgecolor='black', linewidth=2, zorder=5)\n",
    "    ax.annotate(labels[idx], (params[idx], aucs[idx]), \n",
    "                textcoords=\"offset points\", xytext=(0,15), ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Parameters (K)', fontsize=12)\n",
    "ax.set_ylabel('AUC-ROC', fontsize=12)\n",
    "ax.set_title('Parameters vs Performance - Equal Parameters Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ANALYSIS_DIR / 'equal_params_scatter.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_json = {\n",
    "    'benchmark_type': 'Equal Parameters Comparison',\n",
    "    'target_params': '~350K',\n",
    "    'models': [\n",
    "        {\n",
    "            'name': r['model_name'],\n",
    "            'params': r['params'],\n",
    "            'accuracy': float(r['accuracy']),\n",
    "            'auc_roc': float(r['best_auc']),\n",
    "            'f1_score': float(r['best_f1']),\n",
    "            'precision': float(r['precision']),\n",
    "            'recall': float(r['recall']),\n",
    "            'best_threshold': float(r['best_thr']),\n",
    "            'inference_ms': float(r['mean_ms']),\n",
    "            'fps': float(r['fps'])\n",
    "        }\n",
    "        for r in results\n",
    "    ],\n",
    "    'best_model': max(results, key=lambda x: x['best_auc'])['model_name']\n",
    "}\n",
    "\n",
    "with open(ANALYSIS_DIR / 'equal_params_results.json', 'w') as f:\n",
    "    json.dump(results_json, f, indent=2)\n",
    "\n",
    "print(f'Results saved to: {ANALYSIS_DIR / \"equal_params_results.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Summary & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('KESIMPULAN: EQUAL PARAMETERS COMPARISON')\n",
    "print('='*70)\n",
    "print(f'\\nSemua model memiliki ~350K parameters untuk perbandingan yang fair.\\n')\n",
    "\n",
    "# Sort by AUC\n",
    "sorted_results = sorted(results, key=lambda x: x['best_auc'], reverse=True)\n",
    "\n",
    "print('Ranking berdasarkan AUC-ROC:')\n",
    "for i, r in enumerate(sorted_results, 1):\n",
    "    print(f\"  {i}. {r['model_name']}\")\n",
    "    print(f\"     AUC: {r['best_auc']:.4f} | Acc: {r['accuracy']*100:.1f}% | F1: {r['best_f1']:.4f}\")\n",
    "    print(f\"     Precision: {r['precision']:.4f} | Recall: {r['recall']:.4f}\")\n",
    "    print(f\"     Inference: {r['mean_ms']:.2f}ms ({r['fps']:.1f} FPS)\")\n",
    "    print()\n",
    "\n",
    "best = sorted_results[0]\n",
    "print('='*70)\n",
    "print(f'BEST MODEL: {best[\"model_name\"]}')\n",
    "print(f'AUC-ROC: {best[\"best_auc\"]:.4f}')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nFiles saved:')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_training_history.png\"}')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_roc_curves.png\"}')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_confusion_matrices.png\"}')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_performance_comparison.png\"}')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_scatter.png\"}')\n",
    "print(f'  - {ANALYSIS_DIR / \"equal_params_results.json\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
