{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Post-Event Inference - Video Anomaly Detection\n",
    "## Batch Processing untuk Analisis CCTV Recordings\n",
    "\n",
    "Notebook ini untuk:\n",
    "- **Post-event analysis**: Process video recordings setelah event terjadi\n",
    "- **Batch processing**: Process multiple videos secara efisien\n",
    "- **Report generation**: Generate detailed reports dengan timestamps\n",
    "- **Suitable untuk production**: Realistic deployment scenario\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Use Case: CCTV Surveillance System\n",
    "\n",
    "```\n",
    "CCTV Recording (24/7)\n",
    "        â†“\n",
    "Scheduled Processing (setiap 10-15 menit)\n",
    "        â†“\n",
    "Model Inference (batch)\n",
    "        â†“\n",
    "Anomaly Detection\n",
    "        â†“\n",
    "Alert + Report\n",
    "        â†“\n",
    "Security Operator Review\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Import Libraries\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ… Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paths Configuration\n",
    "# =============================================================================\n",
    "NB_ROOT = Path(os.getcwd())\n",
    "ROOT = NB_ROOT / 'DatasetTA'\n",
    "\n",
    "RAW_DIR = ROOT / 'project_data' / 'raw'\n",
    "MODELS_DIR = ROOT / 'project_data' / 'models'\n",
    "OUTPUT_DIR = ROOT / 'project_data' / 'post_event_results'\n",
    "REPORTS_DIR = OUTPUT_DIR / 'reports'\n",
    "VIDEOS_DIR = OUTPUT_DIR / 'annotated_videos'\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VIDEOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model paths\n",
    "YOLO_MODEL = NB_ROOT / 'yolov8n.pt'\n",
    "ANOMALY_MODEL = MODELS_DIR / 'best_model.pt'\n",
    "\n",
    "# Device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "print('='*60)\n",
    "print('âš™ï¸ POST-EVENT INFERENCE SETUP')\n",
    "print('='*60)\n",
    "print(f'Device: {DEVICE}')\n",
    "print(f'Raw Videos: {RAW_DIR}')\n",
    "print(f'Output: {OUTPUT_DIR}')\n",
    "print(f'YOLO Model: {YOLO_MODEL.exists()}')\n",
    "print(f'Anomaly Model: {ANOMALY_MODEL.exists()}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Processing Configuration\n",
    "# =============================================================================\n",
    "class Config:\n",
    "    \"\"\"Configuration for post-event processing\"\"\"\n",
    "    \n",
    "    # Video processing\n",
    "    FRAME_SKIP = 2          # Process every N frames\n",
    "    BUFFER_SIZE = 240       # Frames per segment (8 seconds @ 30fps)\n",
    "    SEGMENT_SIZE = 8        # Number of segments\n",
    "    \n",
    "    # Graph construction\n",
    "    MAX_NODES = 300\n",
    "    GRAPH_DISTANCE_THRESH = 100\n",
    "    GRAPH_TOPK_SPATIAL = 5\n",
    "    GRAPH_TOPK_TEMPORAL = 3\n",
    "    \n",
    "    # Detection\n",
    "    YOLO_CONF = 0.3\n",
    "    YOLO_IOU = 0.5\n",
    "    \n",
    "    # Classification\n",
    "    THRESHOLD = 0.5         # Anomaly threshold\n",
    "    \n",
    "    # Output\n",
    "    SAVE_ANNOTATED_VIDEO = True\n",
    "    SAVE_REPORT = True\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "print('âœ… Configuration loaded')\n",
    "print(f'   Frame skip: {config.FRAME_SKIP}')\n",
    "print(f'   Buffer size: {config.BUFFER_SIZE} frames')\n",
    "print(f'   Threshold: {config.THRESHOLD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Model Architecture (Same as TA_FINAL.ipynb)\n",
    "# =============================================================================\n",
    "def norm_feat(x):\n",
    "    fmin, fmax = x.min(0, keepdim=True)[0], x.max(0, keepdim=True)[0]\n",
    "    return (x - fmin) / (fmax - fmin).clamp(min=1e-6)\n",
    "\n",
    "class STGNN(nn.Module):\n",
    "    def __init__(self, in_dim=10, hid=128, out=128, layers=3, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(in_dim, hid), nn.LayerNorm(hid), nn.GELU(), nn.Dropout(drop))\n",
    "        self.convs = nn.ModuleList([GCNConv(hid, hid) for _ in range(layers)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hid) for _ in range(layers)])\n",
    "        self.att = nn.Sequential(nn.Linear(hid, hid//2), nn.Tanh(), nn.Linear(hid//2, 1))\n",
    "        self.proj = nn.Linear(hid, out)\n",
    "    \n",
    "    def forward(self, x, ei):\n",
    "        h = self.enc(norm_feat(x))\n",
    "        for conv, ln in zip(self.convs, self.norms):\n",
    "            h = h + F.gelu(ln(conv(h, ei)))\n",
    "        att = torch.softmax(self.att(h).squeeze(-1), 0)\n",
    "        return self.proj((h * att.unsqueeze(-1)).sum(0, keepdim=True))\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim=128, heads=4, layers=2, drop=0.3):\n",
    "        super().__init__()\n",
    "        enc = nn.TransformerEncoderLayer(dim, heads, dim*2, drop, 'gelu', batch_first=True)\n",
    "        self.enc = nn.TransformerEncoder(enc, layers)\n",
    "    def forward(self, x): return self.enc(x).mean(1)\n",
    "\n",
    "class AnomalyModel(nn.Module):\n",
    "    def __init__(self, stgnn, trans, dim=128):\n",
    "        super().__init__()\n",
    "        self.stgnn, self.trans = stgnn, trans\n",
    "        self.cls = nn.Sequential(nn.Linear(dim, dim//2), nn.GELU(), nn.Dropout(0.3), nn.Linear(dim//2, 2))\n",
    "    \n",
    "    def forward(self, segs):\n",
    "        dev = next(self.parameters()).device\n",
    "        feats = [self.stgnn(g.x.to(dev), g.edge_index.to(dev) if g.edge_index.numel()>0 \n",
    "                           else torch.empty((2,0), dtype=torch.long, device=dev)) for g in segs]\n",
    "        return self.cls(self.trans(torch.cat(feats, 0).unsqueeze(0)))\n",
    "\n",
    "print('âœ… Model classes defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Load Models\n",
    "# =============================================================================\n",
    "print('ðŸ“¦ Loading models...')\n",
    "\n",
    "# Load YOLO\n",
    "yolo_model = YOLO(str(YOLO_MODEL))\n",
    "print(f'âœ… YOLO loaded: {YOLO_MODEL.name}')\n",
    "\n",
    "# Load Anomaly Model\n",
    "anomaly_model = AnomalyModel(STGNN(), Transformer()).to(DEVICE)\n",
    "checkpoint = torch.load(ANOMALY_MODEL, map_location=DEVICE, weights_only=False)\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    anomaly_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if 'best_auc' in checkpoint:\n",
    "        print(f'   Model AUC: {checkpoint[\"best_auc\"]:.4f}')\n",
    "else:\n",
    "    anomaly_model.load_state_dict(checkpoint)\n",
    "anomaly_model.eval()\n",
    "\n",
    "print(f'âœ… Anomaly model loaded')\n",
    "print(f'   Parameters: {sum(p.numel() for p in anomaly_model.parameters()):,}')\n",
    "print(f'   Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ Graph Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Graph Building Functions\n",
    "# =============================================================================\n",
    "def build_graph_from_detections(detections_buffer: List[List[Dict]], max_nodes: int = 300) -> Data:\n",
    "    \"\"\"Build spatio-temporal graph from detection buffer\"\"\"\n",
    "    nodes = []\n",
    "    node_frames = []\n",
    "    \n",
    "    for frame_idx, frame_dets in enumerate(detections_buffer):\n",
    "        for det in frame_dets:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            \n",
    "            node = [\n",
    "                cx, cy, w, h,\n",
    "                det['confidence'],\n",
    "                det['class_id'],\n",
    "                frame_idx,\n",
    "                w * h,\n",
    "                w / (h + 1e-6),\n",
    "                np.sqrt(w**2 + h**2)\n",
    "            ]\n",
    "            nodes.append(node)\n",
    "            node_frames.append(frame_idx)\n",
    "    \n",
    "    if len(nodes) == 0:\n",
    "        return Data(\n",
    "            x=torch.zeros((1, 10)),\n",
    "            edge_index=torch.empty((2, 0), dtype=torch.long),\n",
    "            node_frames=torch.tensor([0])\n",
    "        )\n",
    "    \n",
    "    if len(nodes) > max_nodes:\n",
    "        indices = np.random.choice(len(nodes), max_nodes, replace=False)\n",
    "        nodes = [nodes[i] for i in indices]\n",
    "        node_frames = [node_frames[i] for i in indices]\n",
    "    \n",
    "    x = torch.tensor(nodes, dtype=torch.float32)\n",
    "    node_frames = torch.tensor(node_frames, dtype=torch.long)\n",
    "    edge_index = build_edges(x, node_frames)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, node_frames=node_frames)\n",
    "\n",
    "def build_edges(x: torch.Tensor, node_frames: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Build spatial and temporal edges\"\"\"\n",
    "    N = x.shape[0]\n",
    "    edges = []\n",
    "    \n",
    "    # Spatial edges\n",
    "    for i in range(N):\n",
    "        frame_i = node_frames[i].item()\n",
    "        cx_i, cy_i = x[i, 0].item(), x[i, 1].item()\n",
    "        same_frame = (node_frames == frame_i).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        distances = []\n",
    "        for j in same_frame:\n",
    "            if i == j:\n",
    "                continue\n",
    "            cx_j, cy_j = x[j, 0].item(), x[j, 1].item()\n",
    "            dist = np.sqrt((cx_i - cx_j)**2 + (cy_i - cy_j)**2)\n",
    "            if dist < config.GRAPH_DISTANCE_THRESH:\n",
    "                distances.append((j.item(), dist))\n",
    "        \n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        for j, _ in distances[:config.GRAPH_TOPK_SPATIAL]:\n",
    "            edges.append([i, j])\n",
    "    \n",
    "    # Temporal edges\n",
    "    for i in range(N):\n",
    "        frame_i = node_frames[i].item()\n",
    "        cx_i, cy_i = x[i, 0].item(), x[i, 1].item()\n",
    "        class_i = x[i, 5].item()\n",
    "        \n",
    "        next_frames = (node_frames > frame_i) & (node_frames <= frame_i + 5)\n",
    "        next_nodes = next_frames.nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        distances = []\n",
    "        for j in next_nodes:\n",
    "            class_j = x[j, 5].item()\n",
    "            if class_i != class_j:\n",
    "                continue\n",
    "            cx_j, cy_j = x[j, 0].item(), x[j, 1].item()\n",
    "            dist = np.sqrt((cx_i - cx_j)**2 + (cy_i - cy_j)**2)\n",
    "            distances.append((j.item(), dist))\n",
    "        \n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        for j, _ in distances[:config.GRAPH_TOPK_TEMPORAL]:\n",
    "            edges.append([i, j])\n",
    "    \n",
    "    if len(edges) == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "    \n",
    "    return torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "def split_segments(g: Data, num_segments: int = 8) -> List[Data]:\n",
    "    \"\"\"Split graph into segments\"\"\"\n",
    "    frames = g.node_frames\n",
    "    max_frame = frames.max().item()\n",
    "    seg_size = (max_frame + 1) / num_segments\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        start = int(i * seg_size)\n",
    "        end = int((i + 1) * seg_size)\n",
    "        mask = (frames >= start) & (frames < end)\n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            seg = Data(x=torch.zeros((1, 10)), edge_index=torch.empty((2, 0), dtype=torch.long))\n",
    "        else:\n",
    "            node_idx = mask.nonzero(as_tuple=True)[0]\n",
    "            seg_x = g.x[node_idx]\n",
    "            \n",
    "            old_to_new = {old.item(): new for new, old in enumerate(node_idx)}\n",
    "            seg_edges = []\n",
    "            for src, dst in g.edge_index.t():\n",
    "                if src.item() in old_to_new and dst.item() in old_to_new:\n",
    "                    seg_edges.append([old_to_new[src.item()], old_to_new[dst.item()]])\n",
    "            \n",
    "            seg_ei = torch.empty((2, 0), dtype=torch.long) if len(seg_edges) == 0 else \\\n",
    "                     torch.tensor(seg_edges, dtype=torch.long).t().contiguous()\n",
    "            \n",
    "            seg = Data(x=seg_x, edge_index=seg_ei)\n",
    "        \n",
    "        segments.append(seg)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "print('âœ… Graph construction functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ Post-Event Processing Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Post-Event Processing Class\n",
    "# =============================================================================\n",
    "class PostEventProcessor:\n",
    "    \"\"\"Process recorded videos for anomaly detection\"\"\"\n",
    "    \n",
    "    def __init__(self, yolo_model, anomaly_model, threshold=0.5):\n",
    "        self.yolo = yolo_model\n",
    "        self.model = anomaly_model\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def detect_objects(self, frame: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Run YOLO detection\"\"\"\n",
    "        results = self.yolo(frame, conf=config.YOLO_CONF, iou=config.YOLO_IOU, verbose=False)\n",
    "        \n",
    "        detections = []\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()\n",
    "                conf = boxes.conf[i].cpu().item()\n",
    "                cls = int(boxes.cls[i].cpu().item())\n",
    "                \n",
    "                detections.append({\n",
    "                    'bbox': [float(x1), float(y1), float(x2), float(y2)],\n",
    "                    'confidence': float(conf),\n",
    "                    'class_id': cls,\n",
    "                    'class_name': self.yolo.names[cls]\n",
    "                })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_buffer(self, detection_buffer: List[List[Dict]]) -> Dict:\n",
    "        \"\"\"Run inference on detection buffer\"\"\"\n",
    "        graph = build_graph_from_detections(detection_buffer, config.MAX_NODES)\n",
    "        graph = graph.to(DEVICE)\n",
    "        segments = split_segments(graph, config.SEGMENT_SIZE)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.amp.autocast('cuda', enabled=USE_AMP):\n",
    "            logits = self.model(segments)\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        prob = torch.softmax(logits, 1)[0, 1].cpu().item()\n",
    "        pred = 'Anomaly' if prob >= self.threshold else 'Normal'\n",
    "        \n",
    "        return {\n",
    "            'prediction': pred,\n",
    "            'probability': prob,\n",
    "            'inference_time': inference_time,\n",
    "            'num_nodes': graph.x.shape[0],\n",
    "            'num_edges': graph.edge_index.shape[1]\n",
    "        }\n",
    "    \n",
    "    def process_video(self, video_path: Path, save_video: bool = True) -> Dict:\n",
    "        \"\"\"Process single video file\"\"\"\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "        \n",
    "        # Video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Output writer\n",
    "        writer = None\n",
    "        if save_video:\n",
    "            output_path = VIDEOS_DIR / f\"{video_path.stem}_annotated.mp4\"\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "        \n",
    "        # Processing\n",
    "        frame_buffer = []\n",
    "        detection_buffer = []\n",
    "        predictions = []\n",
    "        frame_count = 0\n",
    "        \n",
    "        pbar = tqdm(total=total_frames, desc=f\"Processing {video_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Skip frames\n",
    "                if frame_count % config.FRAME_SKIP != 0:\n",
    "                    frame_count += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Detect objects\n",
    "                detections = self.detect_objects(frame)\n",
    "                \n",
    "                # Add to buffer\n",
    "                frame_buffer.append(frame.copy())\n",
    "                detection_buffer.append(detections)\n",
    "                \n",
    "                # Predict when buffer is full\n",
    "                if len(detection_buffer) >= config.BUFFER_SIZE:\n",
    "                    result = self.predict_buffer(detection_buffer)\n",
    "                    \n",
    "                    # Calculate timestamp\n",
    "                    timestamp_sec = frame_count / fps\n",
    "                    timestamp_str = str(timedelta(seconds=int(timestamp_sec)))\n",
    "                    \n",
    "                    predictions.append({\n",
    "                        'frame': frame_count,\n",
    "                        'timestamp': timestamp_str,\n",
    "                        'prediction': result['prediction'],\n",
    "                        'probability': result['probability'],\n",
    "                        'inference_time': result['inference_time']\n",
    "                    })\n",
    "                    \n",
    "                    # Clear buffer (sliding window)\n",
    "                    frame_buffer = frame_buffer[config.BUFFER_SIZE//2:]\n",
    "                    detection_buffer = detection_buffer[config.BUFFER_SIZE//2:]\n",
    "                \n",
    "                # Annotate frame\n",
    "                if save_video and writer:\n",
    "                    annotated = self.annotate_frame(frame, detections, predictions)\n",
    "                    writer.write(annotated)\n",
    "                \n",
    "                frame_count += 1\n",
    "                pbar.update(1)\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            if writer:\n",
    "                writer.release()\n",
    "            pbar.close()\n",
    "        \n",
    "        # Summary\n",
    "        anomaly_count = sum(1 for p in predictions if p['prediction'] == 'Anomaly')\n",
    "        \n",
    "        return {\n",
    "            'video_name': video_path.name,\n",
    "            'video_path': str(video_path),\n",
    "            'total_frames': total_frames,\n",
    "            'fps': fps,\n",
    "            'duration_sec': total_frames / fps,\n",
    "            'predictions': predictions,\n",
    "            'total_predictions': len(predictions),\n",
    "            'anomaly_count': anomaly_count,\n",
    "            'anomaly_rate': anomaly_count / len(predictions) if predictions else 0,\n",
    "            'output_video': str(output_path) if save_video else None\n",
    "        }\n",
    "    \n",
    "    def annotate_frame(self, frame: np.ndarray, detections: List[Dict], predictions: List[Dict]) -> np.ndarray:\n",
    "        \"\"\"Annotate frame with detections and predictions\"\"\"\n",
    "        annotated = frame.copy()\n",
    "        \n",
    "        # Draw detections\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = [int(v) for v in det['bbox']]\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "            cv2.putText(annotated, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw latest prediction\n",
    "        if predictions:\n",
    "            latest = predictions[-1]\n",
    "            pred = latest['prediction']\n",
    "            prob = latest['probability']\n",
    "            \n",
    "            overlay = annotated.copy()\n",
    "            cv2.rectangle(overlay, (10, 10), (400, 80), (0, 0, 0), -1)\n",
    "            annotated = cv2.addWeighted(annotated, 0.7, overlay, 0.3, 0)\n",
    "            \n",
    "            color = (0, 0, 255) if pred == 'Anomaly' else (0, 255, 0)\n",
    "            cv2.putText(annotated, f\"Status: {pred}\", (20, 35), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            cv2.putText(annotated, f\"Probability: {prob:.3f}\", (20, 65), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        return annotated\n",
    "\n",
    "print('âœ… PostEventProcessor class defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Initialize Processor\n",
    "# =============================================================================\n",
    "processor = PostEventProcessor(\n",
    "    yolo_model=yolo_model,\n",
    "    anomaly_model=anomaly_model,\n",
    "    threshold=config.THRESHOLD\n",
    ")\n",
    "\n",
    "print('âœ… Processor initialized')\n",
    "print(f'   Threshold: {config.THRESHOLD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ Scan & Select Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Scan Video Directories (Handle Nested Subdirectories)\n",
    "# =============================================================================\n",
    "def scan_videos(root_dir: Path) -> Dict[str, List[Path]]:\n",
    "    \"\"\"Scan all video files in directory, including nested subdirectories\"\"\"\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    \n",
    "    categories = {}\n",
    "    for subdir in root_dir.iterdir():\n",
    "        if not subdir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        videos = []\n",
    "        \n",
    "        # Check if this directory has subdirectories (like Anomaly-Videos-Part-1/Abuse/)\n",
    "        has_subdirs = any(item.is_dir() for item in subdir.iterdir())\n",
    "        \n",
    "        if has_subdirs:\n",
    "            # Scan nested subdirectories\n",
    "            for nested_dir in subdir.iterdir():\n",
    "                if nested_dir.is_dir():\n",
    "                    for ext in video_extensions:\n",
    "                        videos.extend(nested_dir.glob(f'*{ext}'))\n",
    "        else:\n",
    "            # Scan directly in this directory\n",
    "            for ext in video_extensions:\n",
    "                videos.extend(subdir.glob(f'*{ext}'))\n",
    "        \n",
    "        if videos:\n",
    "            categories[subdir.name] = sorted(videos)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# Scan videos\n",
    "video_categories = scan_videos(RAW_DIR)\n",
    "\n",
    "print('='*60)\n",
    "print('ðŸ“¹ AVAILABLE VIDEOS')\n",
    "print('='*60)\n",
    "for category, videos in video_categories.items():\n",
    "    print(f'{category}: {len(videos)} videos')\n",
    "print('='*60)\n",
    "print(f'Total: {sum(len(v) for v in video_categories.values())} videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Select Videos to Process (1 Anomaly + 1 Normal)\n",
    "# =============================================================================\n",
    "print('='*60)\n",
    "print('ðŸ“¹ SELECTING DEMO VIDEOS')\n",
    "print('='*60)\n",
    "\n",
    "# Select 1 Anomaly video\n",
    "anomaly_video = None\n",
    "anomaly_categories = ['Anomaly-Videos-Part-1', 'Anomaly-Videos-Part-2', \n",
    "                      'Anomaly-Videos-Part-3', 'Anomaly-Videos-Part-4']\n",
    "\n",
    "for cat in anomaly_categories:\n",
    "    if cat in video_categories and len(video_categories[cat]) > 0:\n",
    "        all_videos = video_categories[cat]\n",
    "        anomaly_video = random.choice(all_videos)\n",
    "        print(f'âœ… Anomaly video: {anomaly_video.name}')\n",
    "        print(f'   Category: {cat}')\n",
    "        break\n",
    "\n",
    "if not anomaly_video:\n",
    "    print('âŒ No anomaly videos found')\n",
    "\n",
    "# Select 1 Normal video\n",
    "normal_video = None\n",
    "normal_category = 'Testing_Normal_Videos_Anomaly'\n",
    "\n",
    "if normal_category in video_categories and len(video_categories[normal_category]) > 0:\n",
    "    all_normals = video_categories[normal_category]\n",
    "    normal_video = random.choice(all_normals)\n",
    "    print(f'âœ… Normal video: {normal_video.name}')\n",
    "    print(f'   Category: {normal_category}')\n",
    "else:\n",
    "    for cat in ['Normal_Videos_for_Event_Recognition', 'Training-Normal-Videos-Part-1']:\n",
    "        if cat in video_categories and len(video_categories[cat]) > 0:\n",
    "            all_normals = video_categories[cat]\n",
    "            normal_video = random.choice(all_normals)\n",
    "            print(f'âœ… Normal video: {normal_video.name}')\n",
    "            print(f'   Category: {cat}')\n",
    "            break\n",
    "\n",
    "if not normal_video:\n",
    "    print('âŒ No normal videos found')\n",
    "\n",
    "# Combine selected videos\n",
    "selected_videos = []\n",
    "if anomaly_video:\n",
    "    selected_videos.append(anomaly_video)\n",
    "if normal_video:\n",
    "    selected_videos.append(normal_video)\n",
    "\n",
    "print('='*60)\n",
    "print(f'Total selected: {len(selected_videos)} videos')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ Process Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Process Selected Videos\n",
    "# =============================================================================\n",
    "results = []\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('ðŸš€ PROCESSING VIDEOS')\n",
    "print('='*60)\n",
    "\n",
    "for video_path in selected_videos:\n",
    "    print(f'\\nðŸ“¹ Processing: {video_path.name}')\n",
    "    \n",
    "    try:\n",
    "        result = processor.process_video(\n",
    "            video_path=video_path,\n",
    "            save_video=config.SAVE_ANNOTATED_VIDEO\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f'   âœ… Complete')\n",
    "        print(f'      Duration: {result[\"duration_sec\"]:.1f}s')\n",
    "        print(f'      Predictions: {result[\"total_predictions\"]}')\n",
    "        print(f'      Anomalies: {result[\"anomaly_count\"]} ({result[\"anomaly_rate\"]*100:.1f}%)')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'   âŒ Error: {e}')\n",
    "        continue\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print(f'âœ… PROCESSING COMPLETE: {len(results)}/{len(selected_videos)} videos')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Generate Summary Report\n",
    "# =============================================================================\n",
    "if results:\n",
    "    summary_data = []\n",
    "    for r in results:\n",
    "        summary_data.append({\n",
    "            'Video': r['video_name'],\n",
    "            'Duration (s)': r['duration_sec'],\n",
    "            'Total Predictions': r['total_predictions'],\n",
    "            'Anomaly Count': r['anomaly_count'],\n",
    "            'Anomaly Rate (%)': r['anomaly_rate'] * 100\n",
    "        })\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print('\\n' + '='*60)\n",
    "    print('ðŸ“Š SUMMARY REPORT')\n",
    "    print('='*60)\n",
    "    print(df_summary.to_string(index=False))\n",
    "    print('='*60)\n",
    "    print(f'Total Videos: {len(results)}')\n",
    "    print(f'Total Duration: {df_summary[\"Duration (s)\"].sum():.1f}s')\n",
    "    print(f'Total Predictions: {df_summary[\"Total Predictions\"].sum()}')\n",
    "    print(f'Total Anomalies: {df_summary[\"Anomaly Count\"].sum()}')\n",
    "    print(f'Average Anomaly Rate: {df_summary[\"Anomaly Rate (%)\"].mean():.1f}%')\n",
    "    print('='*60)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    report_path = REPORTS_DIR / f'summary_report_{timestamp}.csv'\n",
    "    df_summary.to_csv(report_path, index=False)\n",
    "    print(f'\\nðŸ’¾ Report saved: {report_path}')\n",
    "else:\n",
    "    print('No results to report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Frame-Level Timeline Analysis\n",
    "# =============================================================================\n",
    "if results:\n",
    "    for result in results:\n",
    "        if not result['predictions']:\n",
    "            continue\n",
    "        \n",
    "        print('\\n' + '='*60)\n",
    "        print(f'ðŸŽ¬ FRAME-LEVEL ANALYSIS: {result[\"video_name\"]}')\n",
    "        print('='*60)\n",
    "        \n",
    "        predictions = result['predictions']\n",
    "        \n",
    "        print(f'\\nVideo Duration: {result[\"duration_sec\"]:.1f}s')\n",
    "        print(f'Total Segments: {len(predictions)}')\n",
    "        print(f'Anomaly Segments: {result[\"anomaly_count\"]}')\n",
    "        print(f'Normal Segments: {len(predictions) - result[\"anomaly_count\"]}')\n",
    "        print('\\n' + '-'*60)\n",
    "        print('TIMELINE (Frame â†’ Time â†’ Prediction â†’ Probability)')\n",
    "        print('-'*60)\n",
    "        \n",
    "        for i, pred in enumerate(predictions, 1):\n",
    "            status = 'ðŸ”´ ANOMALY' if pred['prediction'] == 'Anomaly' else 'ðŸŸ¢ NORMAL'\n",
    "            print(f'{i:2d}. Frame {pred[\"frame\"]:6d} | '\n",
    "                  f'Time {pred[\"timestamp\"]:>8s} | '\n",
    "                  f'{status} | '\n",
    "                  f'Prob {pred[\"probability\"]:.3f}')\n",
    "        \n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Extract Key Frames\n",
    "# =============================================================================\n",
    "def extract_key_frames(video_path: Path, predictions: List[Dict], max_frames: int = 6):\n",
    "    \"\"\"Extract and display key frames where anomalies were detected\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    anomaly_preds = [p for p in predictions if p['prediction'] == 'Anomaly']\n",
    "    \n",
    "    if not anomaly_preds:\n",
    "        print(\"No anomalies detected\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    if len(anomaly_preds) > max_frames:\n",
    "        indices = np.linspace(0, len(anomaly_preds)-1, max_frames, dtype=int)\n",
    "        anomaly_preds = [anomaly_preds[i] for i in indices]\n",
    "    \n",
    "    frames_data = []\n",
    "    for pred in anomaly_preds:\n",
    "        frame_num = pred['frame']\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames_data.append({\n",
    "                'frame': frame_rgb,\n",
    "                'frame_num': frame_num,\n",
    "                'timestamp': pred['timestamp'],\n",
    "                'probability': pred['probability']\n",
    "            })\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not frames_data:\n",
    "        print(\"Could not extract frames\")\n",
    "        return\n",
    "    \n",
    "    n_frames = len(frames_data)\n",
    "    cols = min(3, n_frames)\n",
    "    rows = (n_frames + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    if n_frames == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if rows > 1 else axes\n",
    "    \n",
    "    for i, data in enumerate(frames_data):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(data['frame'])\n",
    "        ax.set_title(f\"Frame {data['frame_num']} | {data['timestamp']}\\nProb: {data['probability']:.3f}\", \n",
    "                    fontsize=10, color='red', weight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        rect = patches.Rectangle((0, 0), data['frame'].shape[1], data['frame'].shape[0],\n",
    "                                linewidth=5, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    for i in range(n_frames, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_path = REPORTS_DIR / f'frames_{video_path.stem}.png'\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f'ðŸ’¾ Saved: {output_path}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Extract frames\n",
    "if results:\n",
    "    for result in results:\n",
    "        if result['anomaly_count'] > 0:\n",
    "            print(f'\\nðŸŽ¬ Extracting frames: {result[\"video_name\"]}')\n",
    "            extract_key_frames(Path(result['video_path']), result['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… Complete!\n",
    "\n",
    "Post-event inference selesai. Check output di:\n",
    "- **Annotated videos**: `DatasetTA/project_data/post_event_results/annotated_videos/`\n",
    "- **Reports**: `DatasetTA/project_data/post_event_results/reports/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
